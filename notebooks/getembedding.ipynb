{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "396e18be",
   "metadata": {},
   "source": [
    "## read sequences from fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3f748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6947bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta( fasta_path, split_char=\"!\", id_field=0):\n",
    "    '''\n",
    "        Reads in fasta file containing multiple sequences.\n",
    "        Split_char and id_field allow to control identifier extraction from header.\n",
    "        E.g.: set split_char=\"|\" and id_field=1 for SwissProt/UniProt Headers.\n",
    "        Returns dictionary holding multiple sequences or only single\n",
    "        sequence, depending on input file.\n",
    "    '''\n",
    "\n",
    "    seqs = dict()\n",
    "    with open( fasta_path, 'r' ) as fasta_f:\n",
    "        count = 0\n",
    "        for line in fasta_f:\n",
    "            # get uniprot ID from header and create new entry\n",
    "            if line.startswith('>'):\n",
    "                uniprot_id = line.replace('>', '').strip().split(split_char)[id_field]\n",
    "                # replace tokens that are mis-interpreted when loading h5\n",
    "                #uniprot_id = uniprot_id.replace(\"/\",\"_\").replace(\".\",\"_\")\n",
    "                uniprot_id = uniprot_id + \"_\" + str(count)\n",
    "                count += 1\n",
    "                seqs[ uniprot_id ] = ''\n",
    "            else:\n",
    "                # repl. all whie-space chars and join seqs spanning multiple lines, drop gaps and cast to upper-case\n",
    "                seq= ''.join( line.split() ).upper().replace(\"-\",\"\")\n",
    "                # repl. all non-standard AAs and map them to unknown/X\n",
    "                seq = seq.replace('U','X').replace('Z','X').replace('O','X')\n",
    "                seqs[ uniprot_id ] += seq\n",
    "    example_id=next(iter(seqs))\n",
    "    print(\"Read {} sequences.\".format(len(seqs)))\n",
    "    print(\"Example:\\n{}\\n{}\".format(example_id,seqs[example_id]))\n",
    "\n",
    "    return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fd61d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 260 sequences.\n",
      "Example:\n",
      "d1a2za__0\n",
      "YSNITVERATLPVRAITKTLRDNGIPATISYSAYPLKAGFIHVPYTPDQVVNKFFLLGKNTPSMCLEAEIKAIELAVKVSLDYLEKDRDDIKIPL\n"
     ]
    }
   ],
   "source": [
    "# read pickle file\n",
    "path = \"../datasets/aligned_seq.fasta\"\n",
    "all_seqs = read_fasta(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c81c48",
   "metadata": {},
   "source": [
    "## load model (using prostt5 as an example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc03383b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zim003/miniforge3/envs/prostt5/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa1801e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5EncoderModel(\n",
       "  (shared): Embedding(150, 1024)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(150, 1024)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 32)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-23): 23 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (k): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (v): Linear(in_features=1024, out_features=4096, bias=False)\n",
       "              (o): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=1024, out_features=16384, bias=False)\n",
       "              (wo): Linear(in_features=16384, out_features=1024, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "tokenizer = T5Tokenizer.from_pretrained('Rostlab/ProstT5', do_lower_case=False)\n",
    "model = T5EncoderModel.from_pretrained(\"Rostlab/ProstT5\").to(device)\n",
    "model.float() if device.type=='cpu' else model.half()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360b6966",
   "metadata": {},
   "source": [
    "## get embeddings (using prostt5 as an example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "170babf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key and value to two separate lists\n",
    "keys = list(all_seqs.keys())\n",
    "values = list(all_seqs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e45f013f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [00:09<00:00, 28.70it/s]\n"
     ]
    }
   ],
   "source": [
    "seq_embeddings = []\n",
    "for i in tqdm(values):\n",
    "    sequences = [i]\n",
    "    length = len(sequences[0])\n",
    "    sequences = [\" \".join(list(re.sub(r\"[UZOB]\", \"X\", sequence))) for sequence in sequences]\n",
    "    sequences = [ \"<AA2fold>\" + \" \" + s if s.isupper() else \"<fold2AA>\" + \" \" + s # this expects 3Di sequences to be already lower-case\n",
    "                      for s in sequences\n",
    "                    ]\n",
    "    ids = tokenizer.batch_encode_plus(sequences,\n",
    "                                  add_special_tokens=True,\n",
    "                                  padding=\"longest\",\n",
    "                                  return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "      embedding_repr = model(\n",
    "              ids.input_ids, \n",
    "              attention_mask=ids.attention_mask\n",
    "              )\n",
    "    emb = embedding_repr.last_hidden_state[0, 1 : length + 1].cpu().numpy()\n",
    "    seq_embeddings.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7731698f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 95, (95, 1024))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seq_embeddings), len(seq_embeddings[0]), seq_embeddings[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f46cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to pickle\n",
    "import pickle\n",
    "output_dict = dict(zip(keys, seq_embeddings))\n",
    "with open(\"../embeddings/prostt5_aligned_embs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(output_dict, f, protocol=4) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prostt5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
